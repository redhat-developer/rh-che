= rh-che dev guide
:toc:
:toc-title:

== Building rh-che
With the exception of the dashboard component, rh-che is a straightforward maven project and can be built as expected. For additional information on the build process for the dashboard component, see link:assembly/fabric8-ide-dashboard-war/README.md[README.md] in the dashboard subcomponent.

[NOTE]
====
The rh-che maven build accommodates the same parameters as the upstream maven build
====
[NOTE]
====
The final build artifacts will be available in `+./assembly/assembly-main/target/eclipse-che-*/+`
====

==== Basic build of all components:
[source,bash]
----
mvn clean install
----

==== Build only only one component and dependents (e.g. dashboard component):
[source,bash]
----
mvn clean install -pl ':fabric8-ide-dashboard-war' --amd
----

==== Build, skipping tests and optional checks
Use the `-Pfast` option:
[source,bash]
----
mvn clean install -Pfast
----
This is equivalent to
[source,bash]
----
mvn -DskipTests=true \
    -Dfindbugs.skip=true \
    -Dmdep.analyze.skip=true \
    -Dlicense.skip=true \
    -Dgwt.compiler.localWorkers=2 -T 1C
----
Which can be slightly sped up further by adding `-Dskip-validate-sources -Dskip-enforce`.

==== Add license headers to all files (fix license check step of full build):
[source,bash]
----
mvn license:format
----

==== Format all files (fix check-format step of full build):
[source,bash]
----
mvn fmt:format
----

== Running Selenium Tests
Rh-Che `functional-tests` are based on selenium framework with Guice injection.
These tests require TestNG profile and listener must be set to `com.redhat.che.selenium.core.RhCheSeleniumTestHandler`

Readme from the repository contains further details, including instructions on how to run tests from the docker image:
https://github.com/redhat-developer/rh-che/tree/master/functional-tests

=== VM options
[source,bash]
----
-Dche.threads=1 -Dche.workspace_pool_size=1 -Dche.host="<RH-Che DEPLOYMENT PATH>" -Dche.port=443 \
  -Dche.protocol=https -Dgrid.mode=false -Dbrowser=GOOGLE_CHROME -Ddriver.port=9515 \
  -Ddriver.version="2.35" -DexcludedGroups=github
----

=== Env variables
[source,bash]
----
CHE_INFRASTRUCTURE=openshift;
CHE_TESTUSER_EMAIL=<email>;
CHE_TESTUSER_OFFLINE__TOKEN=<refresh_token>;
CHE_MULTIUSER=true;
CHE_OFFLINE_TO_ACCESS_TOKEN_EXCHANGE_ENDPOINT=https://auth.<OSD URL>/api/token/refresh;
CHE_TESTUSER_NAME=<username>;
CHE_TESTUSER_PASSWORD=<password>;
----

== Creating docker images
[NOTE]
====
The scripts in this section assume that the maven build was completed successfully and that built artifacts exist at `+./assembly/assembly-main/target/eclipse-che-*/eclipse-che-*+`
====

The simplest way to create a docker image locally is to use the provided script:

[source,bash]
----
./dev-scripts/create_docker_image.sh [docker image name and tag]
----
which simply automates copying the built artifacts to the appropriate directory and running a docker build.

Example:
[source,bash]
----
./dev-scripts/create_docker_image.sh
----

will create the image tagged `fabric8/rh-che-server` (the default), while
[source,bash]
----
./dev-scripts/create_docker_image.sh eclipse/che:local
----
will create the image tagged `eclipse/che:local`

== Deploying rh-che

=== Deploying on minishift locally
[CAUTION]
====
When working on minishift, it is helpful to make sure you are working in the VM's docker environment instead of the default. A good practice is to execute
[source,bash]
----
eval $(minishift oc-env)
eval $(minishift docker-env)
----
before proceeding to ensure docker images are pushed to the minishift docker repository.
====
[CAUTION]
====
When working on rh-che locally, using the multi-user version of the addon, the minimum amount of memory the minishift vm should be given is `4GB` (which is the default). This will allow running a single workspace, if that workspace is limited to a max of `1GB` of memory. To increase the memory given to the minishift VM, use the command
[source,bash]
----
minishift start --memory "5GB"
----
Note however that this only takes effect when starting for the first time -- you will have to `minishift delete` the VM first.
====
The simplest way to deploy locally is to use the bundled minishift addon:

First, install the prerequisites -- a postgres pod and a keycloak pod, configured with the `standalone-keycloak-configurator`:
[source,bash]
----
minishift addons install ./openshift/minishift-addons/rhche-prerequisites
minishift addons apply rhche-prerequisites
----
this can take a while, as the postgres and keycloak pods can take a fairly long time to start. The `configure-keycloak` pod will likely fail and restart a few times before it can complete.

Once this is done, we can deploy rh-che
[source,bash]
----
minishift addons install ./openshift/minishift-addons/rhche
minishift addons apply rhche \
  --addon-env RH_CHE_DOCKER_IMAGE=[*server image to deploy*] \
  --addon-env RH_CHE_VERSION=[*server tag to deploy*]
----
The additional parameters are optional; by default the image used will be `quay.io/openshiftio/che-rh-che-server:latest` and can easily be changed once deployed by modifying the deployment config yaml.

The minishift addon can be removed via
[source,bash]
----
minishift addon remove rhche
minishift addon remove rhche-prerequisites

minishift addon uninstall rhche
minishift addon uninstall rhche-prerequisites
----
[NOTE]
====
The minishift addon uses the yaml files (`rh-che.app.yaml`, `rh-che.config.yaml`) in `./openshift/minishift-addons/rhche/templates` while the dev-cluster deployment script uses the yaml files in `./openshift`. These templates are slightly different
====


=== Deploying to dev-cluster
[WARNING]
====
The `deploy_custom_rh-che.sh` script requires `yq`, a commandline yaml processor. There are (at least) *two* projects named `yq`:

. There is the Python-based `jq` wrapper: https://github.com/kislyuk/yq
. There is the Go-based `jq` replacement: https://github.com/mikefarah/yq

The Go-based implementation has not been tested and potentially has issues, but the dev-script is confirmed to work with the Python-based `yq` with version `>2.6.0`.
====

A prerequisite for deploying on the dev-cluster is pushing a server image to a repository. Once this is done (and assuming you are logged into the dev-cluster locally), deploying rh-che is simply done by using the `./dev-scripts/deploy_custom_rh-che.sh` script:
[source,bash]
----
./dev-scripts/deploy_custom_rh-che.sh \
    -o $(oc whoami -t) \
    -e [openshift-project-name] \
    -r [docker image] \
    -t [docker tag]
----
this will create / update a project with the display name `RH-Che6 Automated Deployment` and name `[openshift-project-name]`. The `-e`, `-r`, and `-t` parameters are optional.
[NOTE]
====
The dev-cluster deployment script uses the yaml files (`rh-che.app.yaml`, `rh-che.config.yaml`) in `./openshift` while the minishift addon uses the yaml files in `./openshift/minishift-addons/rhche/templates`. These templates are slightly different.
====

=== Deploying to OpenShift in general
To be completed

== Roll-updating running deployments
Once rh-che has been deployed (whether it's to minishift or the dev-cluster), making changes is done by:

. Building a new docker image
. Pushing it to your repo (on dev-cluster)
** If using minishift it's sufficient to set the env correctly and build
. Running `oc rollout latest rhche` (assuming you're logged in)

== Debugging rh-che
[INFO]
====
By default, Che deployed on OpenShift will have a liveness probe to check container health. This can interfere with debugging in some cases, as the liveness probe checks `/api/system/state` on `wsmaster`. If you encounter this error, the liveness probe can be removed by editing it out of the `rhche` Deployment Config:
[source,bash]
----
$ oc edit dc rhche
# Find the livenessProbe in the yaml; it should look something like
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /api/system/state
            port: 8080
            scheme: HTTP
          initialDelaySeconds: 120
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 10
# Delete these lines and the deployment will automatically rollout.
----
====
Enabling debugging in Che is done via the environment variable `CHE_DEBUG_SERVER`. By default, this environment variable is set according to the `remote-debugging-enabled` configmap entry when rh-che is deployed.

For deployments done using the minishift addon, the default is `"true"`; for dev-cluster deployments, the default is `false` but can be enabled by modifying the configmap and rolling out a new deployment.

Once debugging is enabled, the easiest way to link a debugger is by using `oc port-forward`:

. First get the name of the pod running rh-che:
+
[source,bash]
----
$ oc get po
NAME                       READY     STATUS      RESTARTS   AGE
configure-keycloak-j7x2w   0/1       Completed   2          4d
keycloak-1-q5d82           1/1       Running     6          4d
postgres-1-bxwv7           1/1       Running     6          4d
rhche-72-49tt6             1/1       Running     4          19h
----

. Enable port-forwarding to the default debug port:
+
[source,bash]
----
oc port-forward rhche-72-49tt6 8000:8000
----

. Connect your remote debugger to `localhost:8000`

Steps 1 and 2 can be shortcut if only one rh-che pod is present (i.e. you're not in the middle of a rolling deploy / the deploy pod is not there):
[source,bash]
----
oc port-forward $(oc get pods --selector="deploymentconfig=rhche" --no-headers=true -o custom-columns=:metadata.name) 8000
----

=== Debugging wsagent pods (workspaces)
_See also_: link:https://github.com/eclipse/che/wiki/Development-Workflow#debugging-workspace-agent[upstream docs]

By default workspace pods expose a JDPA debug port. The easiest way to connect to a workspace pod is again by using `oc port-forward`:

[source,bash]
----
oc port-forward <workspace_pod_name> 4403:4403
----
which will allow connecting a remote debugger to `localhost:4403`

A shortcut, if _only a single workspace is running_, is to use a selector to automatically get the pod name:
[source,bash]
----
oc port-forward $(oc get pods --selector="che.workspace_id" --no-headers=true -o custom-columns=:metadata.name) 4403
----


== All-in-one build and update commands
These commands will do a full build (skipping tests) of rh-che and rollout a new deployment. They assume that they are being executed from this repositorys root directory, and that environment variables
[source,bash]
----
export DOCKER_IMAGE=fabric8/rh-che
export DOCKER_TAG=local
----
have been set appropriately (i.e. to match whatever is currently deployed). To do a limited build (e.g. if working on the dashboard component only), the maven build command can be modified according to the <<Building rh-che>> section.

=== Minishift
Ensure `eval $(minishift docker-env)` and `eval $(minishift oc-env)` have been executed.
[source,bash]
----
mvn -Pfast -Dskip-enforce -Dskip-validate-sources clean install && \
./dev-scripts/create_docker_image.sh ${DOCKER_IMAGE}:${DOCKER_TAG} && \
oc rollout latest rhche
----

=== Dev-cluster
Ensure you are logged in via `oc` and have push rights to the relevant repository.
[source,bash]
----
mvn -Pfast -Dskip-enforce -Dskip-validate-sources clean install && \
./dev-scripts/create_docker_image.sh ${DOCKER_IMAGE}:${DOCKER_TAG} && \
docker push ${DOCKER_IMAGE}:${DOCKER_TAG} && \
oc rollout latest rhche
----
